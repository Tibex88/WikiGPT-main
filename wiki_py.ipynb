{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tibex88/WikiGPT-main/blob/main/wiki_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test\n"
      ],
      "metadata": {
        "id": "C_b7u7Sm6gcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import datetime\n",
        "# import json\n",
        "# DATE = datetime.datetime(2023, 9, 19, 10, 30)\n",
        "# current_datetime = datetime.datetime.now()\n",
        "# current_date = current_datetime.date()\n",
        "\n",
        "# print(json.dumps((current_datetime.isoformat())))\n",
        "# print(\"Current Date and Time:\", current_datetime)\n",
        "# print(\"Current Date:\", current_date)\n",
        "# print(\"DATE:\", DATE)"
      ],
      "metadata": {
        "id": "7PYZHlERuWem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# increase data rate\n",
        "\n",
        "# !mkdir -p ~/.jupyter\n",
        "# !touch ~/.jupyter/jupyter_notebook_config.py\n",
        "# !echo \"c.NotebookApp.iopub_data_rate_limit = int(1e10)\" >> ~/.jupyter/jupyter_notebook_config.py\n",
        "# !pkill jupyter"
      ],
      "metadata": {
        "id": "Ry-UBzhU7m3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEGJb-rw7A3-"
      },
      "outputs": [],
      "source": [
        "# import locale\n",
        "# encoding = locale.getpreferredencoding()\n",
        "# if encoding != \"UTF-8\":\n",
        "#   locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "#   !ls\n",
        "# locale.getpreferredencoding()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wikipedia"
      ],
      "metadata": {
        "id": "rqXPFn3-Ha2a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLmcXO2jeNDs"
      },
      "outputs": [],
      "source": [
        "!pip install -q wikipedia-api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz_ullpbjj3U"
      },
      "source": [
        "## Get article including sections and subsections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDS07ETGX9Wa"
      },
      "outputs": [],
      "source": [
        "import wikipediaapi as wapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMRMP54KmOKK"
      },
      "outputs": [],
      "source": [
        "user_agent = 'Mozilla/5.0 (iPhone; CPU iPhone OS 5_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9B179 Safari/7534.48.3'\n",
        "\n",
        "def get_wikipedia_article(title):\n",
        "    wiki_wiki = wapi.Wikipedia(user_agent = user_agent,language='en', extract_format= wapi.ExtractFormat.WIKI)\n",
        "    page = wiki_wiki.page(title)\n",
        "\n",
        "    if not page.exists():\n",
        "        return None\n",
        "    text = page.text\n",
        "    return text\n",
        "\n",
        "# def get_section_content(section):\n",
        "#     section_title = section.title\n",
        "#     section_content = section.text\n",
        "\n",
        "#     subsections = []\n",
        "#     for subsection in section.sections:\n",
        "#         subsection_title = subsection.title\n",
        "#         subsection_content = subsection.text\n",
        "#         subsections.append((subsection_title, subsection_content))\n",
        "\n",
        "#     return section_title, section_content, subsections\n",
        "\n",
        "# def flatten_array(arr):\n",
        "#     flattened = []\n",
        "#     for sublist in arr:\n",
        "#         if isinstance(sublist, list):\n",
        "#             flattened.extend(sublist)\n",
        "#         else:\n",
        "#             flattened.append(sublist)\n",
        "#     return flattened\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TEST"
      ],
      "metadata": {
        "id": "XThExct7PVCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# title = 'Interstate 90'\n",
        "# article = get_wikipedia_article(title)"
      ],
      "metadata": {
        "id": "KxgVsAu9PUin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Splitter"
      ],
      "metadata": {
        "id": "X5ta1u4uNBKV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJZM4mRN9FCy"
      },
      "outputs": [],
      "source": [
        "!pip install -q  langchain  accelerate bitsandbytes #einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,           # Usually chunk sizes are much larger than this\n",
        "    chunk_overlap  = 20,        # Overlap is needed incase the text is split in odd places\n",
        "    length_function = len,\n",
        ")"
      ],
      "metadata": {
        "id": "Z-gauOe3Ij_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TEST\n"
      ],
      "metadata": {
        "id": "jM_7X2axQXtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text = text_splitter.split_text(article)\n",
        "# text"
      ],
      "metadata": {
        "id": "-JDzfZxXQar2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding"
      ],
      "metadata": {
        "id": "sYxQsYEIMRPI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_lAZwo3Lg2t"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama_index sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mT0mMqtctGl"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
        "from llama_index import LangchainEmbedding\n",
        "\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF9fdDzploSc"
      },
      "outputs": [],
      "source": [
        "def embed(text):\n",
        "    embeddings = []\n",
        "    for i in text:\n",
        "      section_embedding = embed_model.get_text_embedding(i)\n",
        "      embeddings.append(section_embedding)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TEST"
      ],
      "metadata": {
        "id": "ZuItFvobQ6rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings = embed(text)\n",
        "# embeddings"
      ],
      "metadata": {
        "id": "LNU_hJUVQ8ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pinecone Database"
      ],
      "metadata": {
        "id": "w6AfEaqvHiGq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NjBp_cjYdFa"
      },
      "outputs": [],
      "source": [
        "!pip install -q pinecone-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExwpoDsP85DP"
      },
      "source": [
        "## Connect to Pinecone as a vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eomA73CHmhYW"
      },
      "outputs": [],
      "source": [
        "dimension = embed_model.get_text_embedding(\"hello\")\n",
        "len(dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvil07GHbzCF"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "# initialize connection to pinecone\n",
        "pinecone.init(\n",
        "    api_key= 'f0048841-1886-4d17-bffd-a5fe39c183a9',\n",
        "    environment= 'asia-southeast1-gcp-free'\n",
        ")\n",
        "\n",
        "# create the index if it does not exist already\n",
        "index_name = 'wiki'\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=len(dimension),\n",
        "        metric='cosine'\n",
        "    )\n",
        "\n",
        "# connect to the index\n",
        "pinecone_index = pinecone.Index(index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Upload to db"
      ],
      "metadata": {
        "id": "Ol_OY4UwNW6z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqczlubh2oTm"
      },
      "outputs": [],
      "source": [
        "def upsert_to_db(text, embeddings, namespace=None):\n",
        "  if namespace == None:\n",
        "    print('Cant update, there is no namespace value,namespace value is ',namespace)\n",
        "    return False;\n",
        "  else:\n",
        "    print(\"namespace\",namespace)\n",
        "    docs = []\n",
        "    for idx, i in enumerate(text):\n",
        "      docs.append((\n",
        "            str(idx),\n",
        "            embeddings[idx],\n",
        "            {'text': i},\n",
        "        ))\n",
        "    pinecone_index.upsert(namespace=namespace,vectors = docs,batch_size=100, show_progress = True)\n",
        "    return True;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKBjtslSjeIK"
      },
      "source": [
        "## Get from db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrWG0RUrjc4w"
      },
      "outputs": [],
      "source": [
        "def get_data_from_db(query,namespace):\n",
        "    embedded_query = embed_model.get_text_embedding(query)\n",
        "    result = pinecone_index.query(embedded_query, top_k=20, namespace=namespace, includeMetadata=True)\n",
        "    matches = []\n",
        "    for i in result['matches']:\n",
        "      if (i['score'] > 0.6):\n",
        "        print(i.metadata['text'])\n",
        "        matches.append(i.metadata['text'])\n",
        "    return str(matches)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AI\n"
      ],
      "metadata": {
        "id": "r4jMnnzFJ2Ai"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSvKslixfYaq"
      },
      "source": [
        "## Wrap instruction in prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukYOH2JzT9Mu"
      },
      "outputs": [],
      "source": [
        "\n",
        "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
        "  You will be given texts related to a certain topic. Write a summary response that answers the question based on what is discussed in the texts.\n",
        "  Do not mention anything outside of what is provided. Don't answer anything outside the context you are provided.\n",
        "  If there isn't enough context, simply reply \"This topic was not discussed previously\"\n",
        "  \"\"\"\n",
        "\n",
        "SYSTEM_PROMPT = B_SYS + DEFAULT_SYSTEM_PROMPT + E_SYS\n",
        "\n",
        "def get_prompt(instruction):\n",
        "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
        "    return prompt_template\n",
        "\n",
        "def format_prompt(query, context):\n",
        "    return '''\n",
        "    ### Texts:\n",
        "    {context}\n",
        "\n",
        "    ### Question:\n",
        "    {query}\n",
        "    '''.format(context=context, query=query)\n",
        "\n",
        "def format_response(response):\n",
        "    return response.split(\"[/INST]\")[1].replace(\"</s>\",\"\").strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YVX-ok-lC-A"
      },
      "source": [
        "### Login to Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmwtQhVw8fWK"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjDx4gfaJT-q"
      },
      "outputs": [],
      "source": [
        "# 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"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGMVXPLwlHbI"
      },
      "source": [
        "### Define model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGgbiC_ePY_c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig #, LLaMATokenizer, LLaMAForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZdsO7ciPaek"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "                                          use_auth_token=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "                                             device_map='auto',\n",
        "                                             torch_dtype=torch.float16,\n",
        "                                             use_auth_token=True,\n",
        "                                             load_in_4bit=True\n",
        "                                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlYaVuXrQAUR"
      },
      "outputs": [],
      "source": [
        "def generate(prompt_template):\n",
        "    output = \"\"\n",
        "    inputs = tokenizer(\n",
        "        prompt_template,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "    generation_config = GenerationConfig(\n",
        "        temperature=0.6,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2,\n",
        "    )\n",
        "    print(\"Generating...\")\n",
        "    generation_output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        generation_config=generation_config,\n",
        "        return_dict_in_generate=True,\n",
        "        output_scores=True,\n",
        "        max_new_tokens=4028,\n",
        "    )\n",
        "    for s in generation_output.sequences:\n",
        "        output += tokenizer.decode(s)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2ucVHE1N8Vh"
      },
      "outputs": [],
      "source": [
        "# Define a function that runs the model\n",
        "def answer(query,namespace=''):\n",
        "    context = get_data_from_db(query,namespace)\n",
        "\n",
        "    prompt = format_prompt(query, context)\n",
        "    prompt_template = get_prompt(prompt)\n",
        "    output = format_response(generate(prompt_template))\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TEST"
      ],
      "metadata": {
        "id": "2Gx5hp8rVB4R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnIvjZk5cSWb"
      },
      "outputs": [],
      "source": [
        "answer(\"what is the National renewable energy markets are projection ?\", namespace='Renewable energy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer(\"tELL ME ABOUT THE Historical city center\", namespace='History of Rome')"
      ],
      "metadata": {
        "id": "-EBJWg7SO0b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialize Article"
      ],
      "metadata": {
        "id": "P94sAlhPO6RE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvwEPJhmwld7"
      },
      "outputs": [],
      "source": [
        "# embeddings = []\n",
        "# title=('USS Marmora (1862)')\n",
        "def init_article(title):\n",
        "    # check if no title is present\n",
        "     article = get_wikipedia_article(title)\n",
        "     text = text_splitter.split_text(article)\n",
        "     embeddings = embed(text)\n",
        "     is_uploaded = upsert_to_db(text, embeddings,namespace=title)\n",
        "     if is_uploaded: return is_uploaded\n",
        "     else: return is_uploaded"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_article(title='Machine learning')"
      ],
      "metadata": {
        "id": "AdmM6uPSJuZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siiIqST2cSWX"
      },
      "source": [
        "## List of possible queries to test the model\n",
        "- when was Marmora built?\n",
        "- when was the USS Marmora built?\n",
        "- which ship captain was it built for?\n",
        "- what was the other ship that he operated?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#API"
      ],
      "metadata": {
        "id": "ezWmDdsHHly9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLa2hiOmjfw3"
      },
      "outputs": [],
      "source": [
        "!pip install -q flask-ngrok\n",
        "!pip install -q pyngrok==4.1.1\n",
        "!ngrok authtoken 2MBCLllCx6vqHIh1DgyvGTs60iK_7JitdzfDGUU8khCWtopq3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u93hLVLw80pu"
      },
      "outputs": [],
      "source": [
        "!pip install -q flask_cors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_indexes():\n",
        "    return pinecone.list_indexes()\n",
        "\n",
        "def desc_index_stats():\n",
        "  stats = pinecone_index.describe_index_stats()\n",
        "  nm = stats.namespaces\n",
        "  return list(nm)\n",
        "    # pinecone_index.describe_index_stats()\n",
        "\n",
        "# list_indexes()\n",
        "desc_index_stats()"
      ],
      "metadata": {
        "id": "r9CGk1XVXg3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVbSbA71jkKf"
      },
      "outputs": [],
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_cors import CORS\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "\n",
        "#Running the flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "#lallow all origins access\n",
        "CORS(app, origins=['*'])\n",
        "\n",
        "# get articles\n",
        "@app.route(\"/articles\", methods=['GET'])\n",
        "def get_articles():\n",
        "  namespaces = desc_index_stats()\n",
        "  return namespaces\n",
        "\n",
        "# initialize articles\n",
        "@app.route(\"/new article\", methods=['POST'])\n",
        "def POST_articles():\n",
        "  title = request.form.get('title')\n",
        "\n",
        "  print(f\"Received title: {title}\")\n",
        "  is_uploaded = init_article(title)\n",
        "  if is_uploaded:\n",
        "    namespaces = desc_index_stats()\n",
        "    return namespaces\n",
        "  else:\n",
        "    return not (is_uploaded)\n",
        "\n",
        "# query article\n",
        "@app.route(\"/article\", methods=['GET'])\n",
        "def article():\n",
        "    data = request.args\n",
        "    query = data['query']\n",
        "    namespace = data['namespace']\n",
        "    if not query: return \"No query provided\"\n",
        "    if not namespace: return \"no namespace provided\"\n",
        "    print(\"query\" ,query)\n",
        "    print(\"namespace\" ,namespace)\n",
        "    ans = answer(query, namespace)\n",
        "    return ans\n",
        "\n",
        "\n",
        "\n",
        "# test route\n",
        "@app.route(\"/\", methods=['GET'])\n",
        "def test_page():\n",
        "  return '''<form method=\"POST\" action=\"/new article\">\n",
        "    <input type=\"text\" name=\"title\" value=\"article\">\n",
        "    <input type=\"submit\" value=\"Submit\">\n",
        "</form>\n",
        "'''\n",
        "\n",
        "run_with_ngrok(app)\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rqXPFn3-Ha2a",
        "X5ta1u4uNBKV",
        "sYxQsYEIMRPI",
        "w6AfEaqvHiGq",
        "r4jMnnzFJ2Ai",
        "P94sAlhPO6RE"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}